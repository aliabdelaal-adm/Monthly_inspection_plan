#!/usr/bin/env python3
"""
Merge old-shop-list-updated.xlsx into plan-data.json
This script reads shop data from the Excel file and merges it into the JSON plan data.
"""

import json
import sys
import io
import pandas as pd
from datetime import datetime

# Ensure UTF-8 output
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

def load_json_file(filename):
    """Load and parse a JSON file."""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ Error loading {filename}: {e}")
        return None

def save_json_file(filename, data):
    """Save data to a JSON file."""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ Error saving {filename}: {e}")
        return False

def load_excel_shops(filename):
    """Load shop data from Excel file."""
    try:
        # Read Excel file, skipping the first row
        df = pd.read_excel(filename, skiprows=1, header=0)
        
        # Get the first 8 columns that contain shop data
        df_clean = df.iloc[:, :8]
        df_clean.columns = ['Index', 'ADM Code', 'License No', 'Trade Name (EN)', 'Trade Name (AR)', 'Location', 'Area', 'Contact']
        
        # Remove rows where all important columns are NaN
        df_clean = df_clean.dropna(how='all')
        
        # Convert to list of dictionaries
        shops = []
        for idx, row in df_clean.iterrows():
            # Skip header row (first row after cleanup)
            if idx == 0 or str(row['Trade Name (AR)']).strip() in ['TRADE NAME AR.', 'Trade Name (AR)']:
                continue
                
            # Skip if no trade name
            if pd.isna(row['Trade Name (AR)']):
                continue
                
            shop = {
                'adm_code': str(row['ADM Code']) if pd.notna(row['ADM Code']) else None,
                'license_no': str(row['License No']) if pd.notna(row['License No']) else None,
                'name_en': str(row['Trade Name (EN)']).strip() if pd.notna(row['Trade Name (EN)']) else None,
                'name_ar': str(row['Trade Name (AR)']).strip() if pd.notna(row['Trade Name (AR)']) else None,
                'location': str(row['Location']).strip() if pd.notna(row['Location']) else None,
                'map_url': str(row['Area']).strip() if pd.notna(row['Area']) and 'http' in str(row['Area']) else None,
                'contact': str(row['Contact']).strip() if pd.notna(row['Contact']) else None
            }
            shops.append(shop)
        
        return shops
    except Exception as e:
        print(f"âŒ Error loading Excel file {filename}: {e}")
        import traceback
        traceback.print_exc()
        return None

def find_area_by_location(location, areas):
    """Find area ID by location name."""
    if not location:
        return None
    
    # Normalize location string
    location = location.strip()
    
    # Map common location names and variations to area names
    location_map = {
        'Ø³ÙˆÙ‚ Ø§Ù„Ù…ÙŠÙ†Ø§Ø¡': 'Ø³ÙˆÙ‚ Ø§Ù„Ù…ÙŠÙ†Ø§Ø¡',
        'Ø³ÙˆÙ‚ Ø§Ù„ØªØ±Ø§Ø«': 'Ø³ÙˆÙ‚ Ø§Ù„ØªØ±Ø§Ø«',
        'Ø§Ù„Ø­ØµÙ†': 'Ø§Ù„Ø­ØµÙ†',
        'Ø¬Ø²ÙŠØ±Ø© Ø§Ø¨ÙˆØ¸Ø¨ÙŠ, Ø§Ù„Ø­ØµÙ†': 'Ø§Ù„Ø­ØµÙ†',
        'Ø§Ù„Ø®Ø§Ù„Ø¯ÙŠØ©': 'Ø§Ù„Ø®Ø§Ù„Ø¯ÙŠØ©',
        'Ø§Ù„Ø¯Ø§Ù†Ø©': 'Ø§Ù„Ø¯Ø§Ù†Ø©',
        'Ø§Ù„Ø¯Ø§Ù†Ø© Ø§Ù„ÙÙ„Ø§Ø­ Ø¨Ù„Ø§Ø²Ø§': 'Ø§Ù„Ø¯Ø§Ù†Ø©',
        'Ø´Ø§Ø±Ø¹ Ø§Ù„ÙÙ„Ø§Ø­': 'Ø§Ù„Ø¯Ø§Ù†Ø©',
        'Ø§Ù„Ø´Ø§Ù…Ø®Ø©': 'Ø§Ù„Ø´Ø§Ù…Ø®Ø©',
        'Ø§Ù„Ø´Ø§Ù…Ø®Ø© ': 'Ø§Ù„Ø´Ø§Ù…Ø®Ø©',
        'Ø§Ù„Ù…ØµÙØ­': 'Ø§Ù„Ù…ØµÙØ­',
        'Ø§Ù„Ù…ØµÙØ­ ': 'Ø§Ù„Ù…ØµÙØ­',
        'Ø¨Ù†ÙŠ ÙŠØ§Ø³': 'Ø¨Ù†ÙŠ ÙŠØ§Ø³',
        'Ù…Ø¯ÙŠÙ†Ø© Ø®Ù„ÙŠÙØ©': 'Ù…Ø¯ÙŠÙ†Ø© Ø®Ù„ÙŠÙØ©',
        'Ù…Ø¯ÙŠÙ†Ø© Ø®Ù„ÙŠÙØ© ': 'Ù…Ø¯ÙŠÙ†Ø© Ø®Ù„ÙŠÙØ©',
        'ï»£ïºªï»³ï»¨ïº” ïº§ï» ï»´ï»”ïº” ': 'Ù…Ø¯ÙŠÙ†Ø© Ø®Ù„ÙŠÙØ©',
        'Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø²Ø§ÙŠØ¯': 'Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø²Ø§ÙŠØ¯',
        'Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø²Ø§ÙŠØ¯ ': 'Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø²Ø§ÙŠØ¯',
        'Ø¬Ø²ÙŠØ±Ø© ÙŠØ§Ø³': 'Ø¬Ø²ÙŠØ±Ø© ÙŠØ§Ø³',
        'Ø¬Ø²ÙŠØ±Ø© Ø§Ù„Ø±ÙŠÙ…': 'Ø¬Ø²ÙŠØ±Ø© Ø§Ù„Ø±ÙŠÙ…',
        'Ø§Ù„Ø¨Ø§Ù‡ÙŠØ©': 'Ø§Ù„Ø¨Ø§Ù‡ÙŠØ©',
        'Ø§Ù„Ø¨Ø§Ù‡ÙŠØ© ': 'Ø§Ù„Ø¨Ø§Ù‡ÙŠØ©',
        'Ø§Ù„Ø¨Ø§Ù‡ÙŠØ© Ù…Ø²Ø±Ø¹Ø© 278': 'Ø§Ù„Ø¨Ø§Ù‡ÙŠØ©',
        'Ø§Ù„Ø¨Ø·ÙŠÙ†': 'Ø§Ù„Ø¨Ø·ÙŠÙ†',
        ' Ø§Ù„Ø¨Ø·ÙŠÙ†': 'Ø§Ù„Ø¨Ø·ÙŠÙ†',
        'Ø§Ù„Ø²Ø§Ù‡ÙŠØ©': 'Ø§Ù„Ø²Ø§Ù‡ÙŠØ©',
        'Ø§Ù„Ø´Ù‡Ø§Ù…Ø©': 'Ø§Ù„Ø´Ù‡Ø§Ù…Ø©',
        'Ø§Ù„Ø´Ù‡Ø§Ù…Ù‡ ': 'Ø§Ù„Ø´Ù‡Ø§Ù…Ø©',
        'Ø§Ù„ÙˆØ«Ø¨Ø© Ø¬Ù†ÙˆØ¨': 'Ø§Ù„ÙˆØ«Ø¨Ø© Ø¬Ù†ÙˆØ¨',
        'Ø¬Ø²ÙŠØ±Ø© Ø§Ù„Ø³Ø¹Ø¯ÙŠØ§Øª': 'Ø¬Ø²ÙŠØ±Ø© Ø§Ù„Ø³Ø¹Ø¯ÙŠØ§Øª',
        'Ø´Ø§Ø·ÙŠØ¡ Ø§Ù„Ø±Ø§Ø­Ø©': 'Ø´Ø§Ø·ÙŠØ¡ Ø§Ù„Ø±Ø§Ø­Ø©',
        'Ø´Ø§Ø·Ø¦ Ø§Ù„Ø±Ø§Ø­Ø©': 'Ø´Ø§Ø·ÙŠØ¡ Ø§Ù„Ø±Ø§Ø­Ø©',
        'Ø´Ø§Ø·Ø¦ Ø§Ù„Ø±Ø§Ø­Ø© ': 'Ø´Ø§Ø·ÙŠØ¡ Ø§Ù„Ø±Ø§Ø­Ø©',
        'Ø´Ø§Ø·Ù‰Ø¡ Ø§Ù„Ø±Ø§Ø­Ø©': 'Ø´Ø§Ø·ÙŠØ¡ Ø§Ù„Ø±Ø§Ø­Ø©',
        'Ø¢Ù„ Ù†Ù‡ÙŠØ§Ù†': 'Ø¢Ù„ Ù†Ù‡ÙŠØ§Ù†',
        ' Ø¢Ù„ Ù†Ù‡ÙŠØ§Ù†': 'Ø¢Ù„ Ù†Ù‡ÙŠØ§Ù†',
        'Ø±Ø¨Ø¯Ø§Ù†': 'Ø±Ø¨Ø¯Ø§Ù†',
        'Ø§Ù„Ù…Ø´Ø±Ù': 'Ø§Ù„Ù…Ø´Ø±Ù',
        'Ø§Ù„Ù…Ø´Ø±Ù  ': 'Ø§Ù„Ù…Ø´Ø±Ù',
        'Ø§Ù„Ù…Ø´Ø±Ù Ù…ÙˆÙ„ ': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª',
        'Ø§Ù„ÙˆØ­Ø¯Ø© Ù…ÙˆÙ„': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª',
        'Ø´Ø§Ø±Ø¹ Ø§Ù„Ù…Ø·Ø§Ø± ': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª',
        'Ø´Ø§Ø±Ø¹ Ù…Ø¨Ø§Ø±Ùƒ Ø¨Ù† Ù…Ø­Ù…Ø¯': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª',
        'Ø´Ø§Ø±Ø¹ Ø®Ù„ÙŠÙØ© Ø¨Ù† Ø²Ø§ÙŠØ¯ ': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª',
        'Ø§Ù„Ø±ÙŠÙ': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª',
        'Ø§Ù„Ù…Ù†ØªØ²Ù‡ ': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª',
        'Ø§Ù„Ù…Ù†Ù‡Ù„': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª',
        'Ø£Ø¨ÙˆØ¸Ø¨ÙŠ': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª',
        'Ù…ÙŠÙ†Ø§Ø¡  Ø²Ø§ÙŠØ¯': 'Ù…Ø­Ù„Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø§Øª'
    }
    
    area_name = location_map.get(location, location)
    
    # Find matching area
    for area in areas:
        if area['name'] == area_name:
            return area['id']
    
    return None

def normalize_shop_name(name):
    """Normalize shop name for comparison."""
    if not name:
        return ""
    # Remove extra spaces and normalize
    return ' '.join(name.strip().split())

def find_existing_shop(shop_name, existing_shops):
    """Find existing shop by name."""
    normalized_name = normalize_shop_name(shop_name)
    
    for shop in existing_shops:
        existing_normalized = normalize_shop_name(shop.get('name', ''))
        if normalized_name == existing_normalized:
            return shop
    
    return None

def generate_shop_id():
    """Generate a unique shop ID."""
    timestamp = int(datetime.now().timestamp() * 1000)
    return f"shop_{timestamp}"

def merge_excel_to_json(excel_file, json_file):
    """Merge Excel shop data into JSON plan data."""
    print("=== Merging old-shop-list-updated.xlsx into plan-data.json ===")
    print()
    
    # Load files
    print("ğŸ“‚ Loading files...")
    excel_shops = load_excel_shops(excel_file)
    plan_data = load_json_file(json_file)
    
    if not excel_shops or not plan_data:
        print("âŒ Failed to load required files!")
        return False
    
    print(f"âœ… Excel file loaded: {len(excel_shops)} shops")
    print(f"âœ… JSON file loaded: {len(plan_data.get('shops', []))} existing shops")
    print()
    
    # Create backup
    backup_filename = f"{json_file}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    print(f"ğŸ’¾ Creating backup: {backup_filename}")
    if not save_json_file(backup_filename, plan_data):
        print("âŒ Failed to create backup!")
        return False
    
    # Merge data
    print("ğŸ”„ Merging shop data...")
    
    existing_shops = plan_data.get('shops', [])
    areas = plan_data.get('areas', [])
    
    updated_count = 0
    new_count = 0
    skipped_count = 0
    
    for excel_shop in excel_shops:
        # Use Arabic name as primary, fallback to English
        shop_name = excel_shop['name_ar'] or excel_shop['name_en']
        if not shop_name:
            skipped_count += 1
            continue
        
        # Check if shop already exists
        existing_shop = find_existing_shop(shop_name, existing_shops)
        
        if existing_shop:
            # Update existing shop with additional data from Excel
            if excel_shop['adm_code']:
                existing_shop['admCode'] = excel_shop['adm_code']
            if excel_shop['license_no']:
                existing_shop['licenseNo'] = excel_shop['license_no']
            if excel_shop['name_en']:
                existing_shop['nameEn'] = excel_shop['name_en']
            if excel_shop['contact']:
                existing_shop['contact'] = excel_shop['contact']
            if excel_shop['map_url']:
                existing_shop['mapUrl'] = excel_shop['map_url']
            
            # Update area if location is specified and we can find matching area
            if excel_shop['location']:
                area_id = find_area_by_location(excel_shop['location'], areas)
                if area_id:
                    existing_shop['areaId'] = area_id
            
            updated_count += 1
        else:
            # Create new shop
            area_id = find_area_by_location(excel_shop['location'], areas)
            
            new_shop = {
                'id': generate_shop_id(),
                'name': shop_name
            }
            
            if area_id:
                new_shop['areaId'] = area_id
            if excel_shop['adm_code']:
                new_shop['admCode'] = excel_shop['adm_code']
            if excel_shop['license_no']:
                new_shop['licenseNo'] = excel_shop['license_no']
            if excel_shop['name_en']:
                new_shop['nameEn'] = excel_shop['name_en']
            if excel_shop['contact']:
                new_shop['contact'] = excel_shop['contact']
            if excel_shop['map_url']:
                new_shop['mapUrl'] = excel_shop['map_url']
            
            existing_shops.append(new_shop)
            new_count += 1
    
    # Update plan data
    plan_data['shops'] = existing_shops
    plan_data['lastUpdate'] = datetime.now().isoformat()
    
    # Save merged data
    print("ğŸ’¾ Saving merged data...")
    if not save_json_file(json_file, plan_data):
        print("âŒ Failed to save merged data!")
        return False
    
    # Report results
    print()
    print("âœ… Merge completed successfully!")
    print("ğŸ“Š Merge Summary:")
    print(f"   ğŸ”„ Shops updated with Excel data: {updated_count}")
    print(f"   â• New shops added: {new_count}")
    print(f"   â­ï¸  Shops skipped (no name): {skipped_count}")
    print()
    print(f"ğŸ“ˆ Final counts:")
    print(f"   ğŸª Total shops: {len(plan_data.get('shops', []))}")
    print(f"   ğŸ“… Last update: {plan_data.get('lastUpdate')}")
    
    return True

def main():
    excel_file = 'old-shop-list-updated.xlsx'
    json_file = 'plan-data.json'
    
    success = merge_excel_to_json(excel_file, json_file)
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
